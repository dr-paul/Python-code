#doesn't work on all PDFs

#step 1: load libraries
import PyPDF2 #convert simple, text-based PDF files into readable text)
import textract
import pandas as pd
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from collections import Counter

#step 2: write a for-loop to open many files
filename = (r'C:\...\Data\File Name.pdf')

#open allows you to read the file 
pdfFileObj = open(filename, 'rb')

#the pdfReader variable is a readable object that will be parsed
pdfReader = PyPDF2.PdfFileReader(pdfFileObj)

#discerning the number of pages will allow us to parse through all the pages 
num_pages = pdfReader.numPages
count = 0
text = ""

#the while loop will read each page 
while count < num_pages:
  pageObj = pdfReader.getPage(count)
  count +=1
  text += pageObj.extractText()


#this if statement exists to check if the above library returned words. It's done because PyPDF2 cannot read scanned files
if text != "":
  text = text
else:
  text = textract.process(fileurl, method='tesseract', language='eng')


#now we have a text variable that contains all the text derived from our PDF file. Type print(text) to see what it contains. It likely contains a lot of spaces, possible junk such as '\n,' etc.
#now we will clean our text variable and return it as a list of keywords

#step 3: convert text into keywords

#the word_tokenize() function will break our text phrases into individual words 
tokens = word_tokenize(text)

#we'll create a new list that contains punctuation we wish to clean 
punctuations = ['(',')',';',':','[',']',',']

#we initialise the stopwords variable, which is a list of words like 'the', 'I', 'and', etc... that don't hold much value as keywords
stop_words = stopwords.words('english')

#we create a list comprehension that only returns a list of words that are NOT IN stop_words and NOT IN punctuations
keywords = [word for word in tokens if not word in stop_words and not word in punctuations]

#export to Excel
wordcount = Counter(keywords)
df = pd.DataFrame.from_dict(wordcount, orient='index').reset_index()
df.to_csv(r'C:\...\Data\Word_Freq.csv')
